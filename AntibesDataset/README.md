# Antibes dataset
To test our implementation on a real dataset, we decided to use a set of data coming from the IoT system of Antibes, a city in the south of France. This dataset is private because it contains sensitive information about the water consumption and water pipeline maintenance in the city. This also shows how our approach can be helpful for public institutions. This dataset was collected from diﬀerent sensors that measure the water consumption in diﬀerent neighbourhoods of the city. With minor adjustments, the solution can constitute a valid framework applicable to other purposes, such as electricity consumption and waste management. The dataset is an extract of one month of measurements and each sample is a time series containing 96 values (one every 15 minutes). Each sample is labelled with the name of the neighbourhood and the dataset has been normalized before the training. Our goal is to anonymize the dataset by generating a new one that contains the same number of records and the same distribution as the original dataset. This new dataset will protect the privacy of the users present in the original dataset. Indeed, by looking at the real data, it is possible to correlate the water consumption of the inhabitants of diﬀerent parts of the city with their habits. Diﬀerential privacy guarantees that each sample does not inﬂuence analyses more than a certain threshold. In this way, anomalous situations such as maintenance works, a failure in a water pipe, or unexpected water usage by a person living in a certain area, are protected and kept private. The figures below compare real samples and the generated ones. We used diﬀerent levels of anonymization, characterized by diﬀerent values of epsilon, going from non-anonymized to epsilon = 6. In particular, we plot the comparison between a generated sample and the closest (in terms of dynamic time warping distance) sample coming from the original data. We can see from this ﬁrst graphical assessment, that the distribution of the original time series is kept. When the level of privacy increases, the curves tend to be smoother, hiding some of the variability of the original data. However, in most kinds of analysis this variability is not useful, and the overall distribution constitutes the main source of information. In addition to a qualitative analysis we tried to provide some metrics to evaluate the results. Unfortunately, we realized that it is diﬃcult at the moment to provide a good analysis in this scenario. The DTW, indeed, simply verify that there is a similar time-series in the real samples but it does not take into account the variability of the results. This is a well-known problem in the Generative Adversarial Network ﬁeld. While for images the inception score has become the standard measure to evaluate the performance of a GAN, there is no counterpart for the assessment of time-series. We believe that this represents an interesting area of research for the future, because the impact will not be limited to research in the subject of privacy and anonymization, but it will also inﬂuence the entire ﬁeld of generative models.

![Alt text](Antibes_Adam.png?raw=true "Title")
Generated sample from a non-anonymized GAN (in blue) and closest sample present in the dataset, in terms of dynamic time warping (in orange). There are 96 values for each daily time series, one value every 15 minutes.
 
![Alt text](Antibes_dp.png?raw=true "Title")
Generated sample from a dp-GAN epsilon = 6 (in blue) and closest sample present in the dataset, in terms of dynamic time warping (in orange).


